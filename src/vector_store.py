"""
Vector Store - VektÃ¶r Depolama ModÃ¼lÃ¼

Bu modÃ¼l, embedding vektÃ¶rlerini depolar ve benzerlik aramasÄ± yapar.

RAG Sistemindeki RolÃ¼:
- Chunk embedding'lerini kalÄ±cÄ± olarak saklar
- HÄ±zlÄ± benzerlik aramasÄ± saÄŸlar
- Metadata ile filtreleme imkanÄ± sunar

KullanÄ±lan Teknoloji: ChromaDB
- AÃ§Ä±k kaynak vektÃ¶r veritabanÄ±
- Lokal Ã§alÄ±ÅŸÄ±r (sunucu gerektirmez)
- KalÄ±cÄ± depolama desteÄŸi
- Metadata filtreleme

Benzerlik AramasÄ± NasÄ±l Ã‡alÄ±ÅŸÄ±r?
1. Sorgu metni embed edilir â†’ sorgu vektÃ¶rÃ¼
2. TÃ¼m chunk vektÃ¶rleri ile mesafe hesaplanÄ±r
3. En yakÄ±n K vektÃ¶r dÃ¶ndÃ¼rÃ¼lÃ¼r
"""

import os
from typing import List, Dict, Optional, Any
from dataclasses import dataclass


@dataclass
class SearchResult:
    """Arama sonucunu temsil eden veri sÄ±nÄ±fÄ±"""

    content: str  # Chunk iÃ§eriÄŸi
    metadata: Dict  # Chunk metadata'sÄ±
    distance: float  # Sorguya olan uzaklÄ±k (dÃ¼ÅŸÃ¼k = daha benzer)
    score: float  # Benzerlik skoru (yÃ¼ksek = daha benzer)

    def __repr__(self):
        preview = self.content[:50] + "..." if len(self.content) > 50 else self.content
        return f"SearchResult(score={self.score:.3f}, preview='{preview}')"


class VectorStore:
    """
    VektÃ¶r Deposu (ChromaDB Wrapper)

    Embedding vektÃ¶rlerini depolar ve benzerlik aramasÄ± yapar.

    Ã–rnek kullanÄ±m:
    >>> store = VectorStore(collection_name="my_docs")
    >>> store.add_documents(chunks, embeddings)
    >>> results = store.search(query_embedding, top_k=5)
    """

    def __init__(
        self,
        collection_name: str = "rag_documents",
        persist_directory: str = "./chroma_db",
    ):
        """
        Args:
            collection_name: Koleksiyon adÄ± (grup/tablo benzeri)
            persist_directory: VeritabanÄ± kayÄ±t dizini
        """
        self.collection_name = collection_name
        self.persist_directory = persist_directory
        self.client = None
        self.collection = None

        self._initialize_db()

    def _initialize_db(self):
        """ChromaDB'yi baÅŸlatÄ±r."""
        try:
            import chromadb

            print(f"ğŸ”„ ChromaDB baÅŸlatÄ±lÄ±yor...")

            # KalÄ±cÄ± depolama ile client oluÅŸtur
            self.client = chromadb.PersistentClient(
                path=self.persist_directory,
            )

            # Koleksiyonu al veya oluÅŸtur
            self.collection = self.client.get_or_create_collection(
                name=self.collection_name,
                metadata={"description": "RAG document embeddings"},
            )

            doc_count = self.collection.count()
            print(
                f"âœ… Koleksiyon hazÄ±r: '{self.collection_name}' ({doc_count} dÃ¶kÃ¼man)"
            )

        except ImportError:
            raise ImportError(
                "chromadb paketi gerekli!\n" "Kurulum: pip install chromadb"
            )

    def add_documents(
        self,
        chunks: List,
        embeddings: List[List[float]],
        ids: Optional[List[str]] = None,
    ) -> int:
        """
        Chunk'larÄ± ve embedding'lerini depoya ekler.

        Args:
            chunks: Chunk nesnelerinin listesi
            embeddings: Embedding vektÃ¶rlerinin listesi
            ids: Benzersiz ID'ler (opsiyonel, otomatik oluÅŸturulur)

        Returns:
            Eklenen dÃ¶kÃ¼man sayÄ±sÄ±
        """
        if not chunks or not embeddings:
            print("âš ï¸  Eklenecek dÃ¶kÃ¼man yok!")
            return 0

        if len(chunks) != len(embeddings):
            raise ValueError("Chunk ve embedding sayÄ±larÄ± eÅŸleÅŸmiyor!")

        # ID'leri hazÄ±rla
        if ids is None:
            ids = [f"doc_{i}_{hash(chunk.content)}" for i, chunk in enumerate(chunks)]

        # Ä°Ã§erikleri ve metadata'larÄ± ayÄ±r
        documents = [chunk.content for chunk in chunks]
        metadatas = []

        for chunk in chunks:
            # Metadata'yÄ± ChromaDB formatÄ±na Ã§evir
            meta = {}
            if hasattr(chunk, "metadata") and chunk.metadata:
                for key, value in chunk.metadata.items():
                    # ChromaDB sadece string, int, float, bool kabul eder
                    if isinstance(value, (str, int, float, bool)):
                        meta[key] = value
                    else:
                        meta[key] = str(value)
            metadatas.append(meta)

        # ChromaDB'ye ekle
        print(f"ğŸ”„ {len(chunks)} chunk ekleniyor...")

        self.collection.add(
            ids=ids, documents=documents, embeddings=embeddings, metadatas=metadatas
        )

        print(f"âœ… {len(chunks)} chunk baÅŸarÄ±yla eklendi!")
        return len(chunks)

    def search(
        self,
        query_embedding: List[float],
        top_k: int = 5,
        where: Optional[Dict] = None,
        where_document: Optional[Dict] = None,
    ) -> List[SearchResult]:
        """
        Benzerlik aramasÄ± yapar.

        Args:
            query_embedding: Sorgu vektÃ¶rÃ¼
            top_k: DÃ¶ndÃ¼rÃ¼lecek sonuÃ§ sayÄ±sÄ±
            where: Metadata filtresi (Ã¶rn: {"source": "doc1.txt"})
            where_document: Ä°Ã§erik filtresi (Ã¶rn: {"$contains": "python"})

        Returns:
            SearchResult listesi (skora gÃ¶re sÄ±ralÄ±)
        """
        # Sorguyu Ã§alÄ±ÅŸtÄ±r
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            where=where,
            where_document=where_document,
            include=["documents", "metadatas", "distances"],
        )

        # SonuÃ§larÄ± SearchResult nesnelerine dÃ¶nÃ¼ÅŸtÃ¼r
        search_results = []

        if results and results["documents"] and results["documents"][0]:
            documents = results["documents"][0]
            metadatas = (
                results["metadatas"][0]
                if results["metadatas"]
                else [{}] * len(documents)
            )
            distances = (
                results["distances"][0]
                if results["distances"]
                else [0] * len(documents)
            )

            for doc, meta, dist in zip(documents, metadatas, distances):
                # Distance'Ä± score'a Ã§evir (1 / (1 + distance))
                # DÃ¼ÅŸÃ¼k distance = yÃ¼ksek score
                score = 1 / (1 + dist)

                search_results.append(
                    SearchResult(
                        content=doc, metadata=meta or {}, distance=dist, score=score
                    )
                )

        return search_results

    def delete_collection(self):
        """Koleksiyonu tamamen siler."""
        if self.client and self.collection_name:
            self.client.delete_collection(self.collection_name)
            print(f"ğŸ—‘ï¸  Koleksiyon silindi: {self.collection_name}")

    def get_stats(self) -> Dict[str, Any]:
        """Koleksiyon istatistiklerini dÃ¶ndÃ¼rÃ¼r."""
        return {
            "collection_name": self.collection_name,
            "document_count": self.collection.count(),
            "persist_directory": self.persist_directory,
        }

    def clear(self):
        """TÃ¼m dÃ¶kÃ¼manlarÄ± siler ama koleksiyonu korur."""
        # Mevcut koleksiyonu sil ve yeniden oluÅŸtur
        self.client.delete_collection(self.collection_name)
        self.collection = self.client.get_or_create_collection(
            name=self.collection_name,
            metadata={"description": "RAG document embeddings"},
        )
        print(f"ğŸ§¹ Koleksiyon temizlendi: {self.collection_name}")


# Test iÃ§in
if __name__ == "__main__":
    import tempfile

    # GeÃ§ici dizinde test
    with tempfile.TemporaryDirectory() as tmpdir:
        print("\n" + "=" * 60)
        print("VECTOR STORE TEST")
        print("=" * 60)

        # Store oluÅŸtur
        store = VectorStore(collection_name="test_collection", persist_directory=tmpdir)

        # Test verisi (basit mock chunk ve embedding)
        class MockChunk:
            def __init__(self, content, metadata=None):
                self.content = content
                self.metadata = metadata or {}

        chunks = [
            MockChunk("Python bir programlama dilidir", {"source": "doc1.txt"}),
            MockChunk("Machine learning yapay zeka dalÄ±dÄ±r", {"source": "doc2.txt"}),
            MockChunk(
                "Web geliÅŸtirme frontend ve backend iÃ§erir", {"source": "doc3.txt"}
            ),
        ]

        # Basit rastgele embedding (gerÃ§ek projede Embedder kullanÄ±lÄ±r)
        import random

        embeddings = [[random.random() for _ in range(384)] for _ in chunks]

        # Ekle
        store.add_documents(chunks, embeddings)

        # Ara
        query_embedding = embeddings[0]  # Ä°lk dÃ¶kÃ¼manÄ±n embedding'i ile ara
        results = store.search(query_embedding, top_k=2)

        print("\nğŸ” Arama SonuÃ§larÄ±:")
        for i, result in enumerate(results, 1):
            print(f"  {i}. Score: {result.score:.3f} - {result.content[:50]}")

        # Ä°statistikler
        print(f"\nğŸ“Š Ä°statistikler: {store.get_stats()}")
