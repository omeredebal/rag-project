#!/usr/bin/env python3
"""
RAG Demo Script

Bu script, RAG sisteminin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶sterir.
AdÄ±m adÄ±m tÃ¼m pipeline'Ä± Ã§alÄ±ÅŸtÄ±rÄ±r.

KullanÄ±m:
    python demo.py
"""

import os
import sys

# Proje kÃ¶k dizinini path'e ekle
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)


def print_banner():
    """HoÅŸgeldin mesajÄ±"""
    print(
        """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                              â•‘
â•‘     ğŸ” RAG (Retrieval-Augmented Generation) Demo             â•‘
â•‘                                                              â•‘
â•‘     Bu demo, RAG sisteminin tÃ¼m bileÅŸenlerini                â•‘
â•‘     adÄ±m adÄ±m gÃ¶sterir.                                      â•‘
â•‘                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    )


def step1_document_loading():
    """AdÄ±m 1: DÃ¶kÃ¼man YÃ¼kleme"""
    print("\n" + "=" * 60)
    print("ğŸ“š ADIM 1: DÃ–KÃœMAN YÃœKLEME (Document Loading)")
    print("=" * 60)

    print(
        """
    Document Loader, ham dÃ¶kÃ¼manlarÄ± sisteme alÄ±r.
    - DosyalarÄ± okur (.txt, .md)
    - Metadata ekler (dosya adÄ±, boyut, tarih)
    - Sonraki aÅŸamaya hazÄ±rlar
    """
    )

    from src.document_loader import DocumentLoader

    loader = DocumentLoader()
    docs = loader.load_directory("data/")

    print(f"\nğŸ“Š SonuÃ§: {len(docs)} dÃ¶kÃ¼man yÃ¼klendi")

    for doc in docs:
        print(
            f"   - {doc.metadata.get('filename')}: {doc.metadata.get('char_count')} karakter"
        )

    return docs


def step2_chunking(docs):
    """AdÄ±m 2: Metin ParÃ§alama"""
    print("\n" + "=" * 60)
    print("âœ‚ï¸  ADIM 2: METÄ°N PARÃ‡ALAMA (Chunking)")
    print("=" * 60)

    print(
        """
    Chunking, uzun metinleri kÃ¼Ã§Ã¼k parÃ§alara bÃ¶ler.
    - Embedding modelleri iÃ§in uygun boyut (max ~500 karakter)
    - Overlap ile baÄŸlam korunur
    - Her chunk baÄŸÄ±msÄ±z aranabilir olur
    """
    )

    from src.chunker import TextChunker

    chunker = TextChunker(chunk_size=500, chunk_overlap=50)
    chunks = chunker.chunk_documents(docs)

    print(f"\nğŸ“Š SonuÃ§: {len(chunks)} chunk oluÅŸturuldu")
    print("\nğŸ“ Ä°lk 3 chunk:")

    for i, chunk in enumerate(chunks[:3], 1):
        preview = chunk.content[:100].replace("\n", " ")
        print(f"\n   Chunk {i} ({len(chunk.content)} karakter):")
        print(f"   '{preview}...'")

    return chunks


def step3_embedding(chunks):
    """AdÄ±m 3: Embedding OluÅŸturma"""
    print("\n" + "=" * 60)
    print("ğŸ”¢ ADIM 3: EMBEDDING OLUÅTURMA (Vectorization)")
    print("=" * 60)

    print(
        """
    Embedding, metni sayÄ±sal vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
    - Her chunk â†’ 384 boyutlu vektÃ¶r
    - Benzer anlamlar â†’ YakÄ±n vektÃ¶rler
    - Semantic arama mÃ¼mkÃ¼n olur
    """
    )

    from src.embedder import Embedder

    embedder = Embedder()

    # Ä°lk chunk'Ä± embed et ve gÃ¶ster
    sample_embedding = embedder.embed_text(chunks[0].content)

    print(f"\nğŸ“Š Embedding boyutu: {len(sample_embedding)}")
    print(f"   Ä°lk 10 deÄŸer: {[round(x, 4) for x in sample_embedding[:10]]}")

    # TÃ¼m chunk'larÄ± embed et
    contents = [c.content for c in chunks]
    all_embeddings = embedder.embed_texts(contents)

    print(f"\nâœ… {len(all_embeddings)} chunk embed edildi")

    return embedder, all_embeddings


def step4_vector_store(chunks, embeddings):
    """AdÄ±m 4: VektÃ¶r Depolama"""
    print("\n" + "=" * 60)
    print("ğŸ’¾ ADIM 4: VEKTÃ–R DEPOLAMA (Vector Store)")
    print("=" * 60)

    print(
        """
    Vector Store, embedding'leri depolar ve aranabilir kÄ±lar.
    - ChromaDB kullanÄ±yoruz (lokal, Ã¼cretsiz)
    - KalÄ±cÄ± depolama
    - HÄ±zlÄ± benzerlik aramasÄ±
    """
    )

    from src.vector_store import VectorStore

    store = VectorStore(
        collection_name="demo_collection", persist_directory="./demo_chroma_db"
    )

    # Temizle ve ekle
    store.clear()
    count = store.add_documents(chunks, embeddings)

    stats = store.get_stats()
    print(f"\nğŸ“Š Depolanan chunk sayÄ±sÄ±: {stats['document_count']}")

    return store


def step5_retrieval(embedder, store):
    """AdÄ±m 5: Bilgi Getirme"""
    print("\n" + "=" * 60)
    print("ğŸ” ADIM 5: BÄ°LGÄ° GETÄ°RME (Retrieval)")
    print("=" * 60)

    print(
        """
    Retrieval, sorguya en uygun chunk'larÄ± getirir.
    - Sorgu embed edilir
    - Vector store'da benzerlik aramasÄ±
    - En alakalÄ± K chunk dÃ¶ndÃ¼rÃ¼lÃ¼r
    """
    )

    from src.retriever import Retriever

    retriever = Retriever(embedder=embedder, vector_store=store, top_k=3)

    # Test sorgusu
    test_query = "Python programlama dili nedir ve ne iÃ§in kullanÄ±lÄ±r?"
    print(f"\nâ“ Test Sorgusu: '{test_query}'")

    results = retriever.retrieve(test_query)

    print(f"\nğŸ“Š Bulunan {len(results)} sonuÃ§:")

    for i, r in enumerate(results, 1):
        print(f"\n   [{i}] Skor: {r.score:.3f}")
        preview = r.content[:150].replace("\n", " ")
        print(f"       '{preview}...'")

    return retriever


def step6_generation(retriever):
    """AdÄ±m 6: YanÄ±t Ãœretme"""
    print("\n" + "=" * 60)
    print("ğŸ¤– ADIM 6: YANIT ÃœRETME (Generation)")
    print("=" * 60)

    print(
        """
    Generation, LLM ile yanÄ±t Ã¼retir.
    - Retrieved context LLM'e verilir
    - LLM, context'e dayalÄ± yanÄ±t Ã¼retir
    - Ollama ile lokal LLM kullanÄ±yoruz
    """
    )

    from src.generator import Generator

    generator = Generator(model="llama3.2")

    # Test sorusu ve context
    question = "Python'un temel Ã¶zellikleri nelerdir?"
    context = retriever.retrieve_with_context(question)

    print(f"\nâ“ Soru: '{question}'")
    print(f"\nğŸ“„ Context (kÄ±saltÄ±lmÄ±ÅŸ):\n   {context[:300]}...")

    print("\nâ³ LLM yanÄ±t Ã¼retiyor...")
    answer = generator.generate(question=question, context=context)

    print(f"\nğŸ’¬ YANIT:\n{answer}")

    return generator


def step7_full_pipeline():
    """AdÄ±m 7: Tam Pipeline Demo"""
    print("\n" + "=" * 60)
    print("ğŸš€ ADIM 7: TAM RAG PIPELINE")
    print("=" * 60)

    print(
        """
    Åimdi tÃ¼m bileÅŸenleri birleÅŸtiren RAGPipeline sÄ±nÄ±fÄ±nÄ±
    kullanarak end-to-end demo yapacaÄŸÄ±z.
    """
    )

    from src.rag_pipeline import RAGPipeline

    # Pipeline oluÅŸtur
    rag = RAGPipeline(
        collection_name="full_demo", persist_directory="./full_demo_db", top_k=3
    )

    # DÃ¶kÃ¼manlarÄ± indexle
    rag.index_documents("data/", clear_existing=True)

    # Sorular sor
    questions = [
        "Python'u kim geliÅŸtirdi?",
        "Makine Ã¶ÄŸrenmesi tÃ¼rleri nelerdir?",
        "RAG nedir ve nasÄ±l Ã§alÄ±ÅŸÄ±r?",
        "Derin Ã¶ÄŸrenme iÃ§in hangi kÃ¼tÃ¼phaneler kullanÄ±lÄ±r?",
    ]

    print("\n" + "-" * 60)
    print("ğŸ“‹ SORU-CEVAP DEMOsu")
    print("-" * 60)

    for q in questions:
        response = rag.query(q)

        print(f"\nâ“ SORU: {q}")
        print(f"\nğŸ’¬ YANIT: {response.answer}")
        print(f"\nğŸ“š Kaynaklar: {response.sources}")
        print("\n" + "." * 60)

    return rag


def interactive_mode(rag):
    """Ä°nteraktif soru-cevap modu"""
    print("\n" + "=" * 60)
    print("ğŸ’¬ Ä°NTERAKTÄ°F MOD")
    print("=" * 60)
    print(
        """
    ArtÄ±k kendi sorularÄ±nÄ±zÄ± sorabilirsiniz!
    Ã‡Ä±kmak iÃ§in 'q' veya 'exit' yazÄ±n.
    """
    )

    while True:
        try:
            question = input("\nâ“ Sorunuz: ").strip()

            if question.lower() in ["q", "exit", "quit", "Ã§Ä±k"]:
                print("\nğŸ‘‹ GÃ¶rÃ¼ÅŸÃ¼rÃ¼z!")
                break

            if not question:
                continue

            response = rag.query(question)
            print(f"\nğŸ’¬ YANIT:\n{response.answer}")

            if response.sources:
                print(f"\nğŸ“š Kaynaklar: {', '.join(response.sources)}")

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ GÃ¶rÃ¼ÅŸÃ¼rÃ¼z!")
            break


def main():
    """Ana demo fonksiyonu"""
    print_banner()

    try:
        # AdÄ±m adÄ±m demo
        docs = step1_document_loading()
        chunks = step2_chunking(docs)
        embedder, embeddings = step3_embedding(chunks)
        store = step4_vector_store(chunks, embeddings)
        retriever = step5_retrieval(embedder, store)
        generator = step6_generation(retriever)
        rag = step7_full_pipeline()

        # Ä°nteraktif mod
        print("\n" + "=" * 60)
        print("âœ… DEMO TAMAMLANDI!")
        print("=" * 60)

        try_interactive = (
            input("\nğŸ® Ä°nteraktif moda geÃ§mek ister misiniz? (e/h): ").strip().lower()
        )

        if try_interactive in ["e", "evet", "y", "yes"]:
            interactive_mode(rag)

    except ImportError as e:
        print(f"\nâŒ Eksik paket hatasÄ±: {e}")
        print("\nLÃ¼tfen gereken paketleri yÃ¼kleyin:")
        print("   pip install -r requirements.txt")
        print("\nOllama iÃ§in:")
        print("   brew install ollama")
        print("   ollama pull llama3.2")

    except Exception as e:
        print(f"\nâŒ Hata: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
